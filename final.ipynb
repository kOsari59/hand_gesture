{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 필요한 모듈들을 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import save_model,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input ,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import math\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 블러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O  파일 길이 :  805\n",
      "V  파일 길이 :  624\n",
      "paper  파일 길이 :  805\n",
      "rock  파일 길이 :  621\n",
      "side  파일 길이 :  805\n",
      "ok 3660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmc59\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "caltech_dir = \"./HandGesture\\images\" #학습데이터\n",
    "categories = [\"O\", \"V\", \"paper\", \"rock\",\"side\"] #카테고리 나누기\n",
    "nb_classes = len(categories)#카테고리 길이 결정\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "pixels = image_h * image_w * 3 #픽셀은 64*64에 3층\n",
    "X = []\n",
    "y = []\n",
    "#카테고리 수만큼 전처리 원핫 인코딩\n",
    "for idx, cat in enumerate(categories): \n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "    image_dir = caltech_dir + \"/\" + cat #cat의 폴더 열기\n",
    "    files = glob.glob(image_dir+\"/*.jpg\") #cat에 있는 jpg로 끝나는 파일 읽어오기\n",
    "    print(cat, \" 파일 길이 : \", len(files))#전체 파일 수 i 파일 수 f는 파일 이름\n",
    "    for i, f in enumerate(files):#파일 수만큼 반복\n",
    "        img = cv2.imread(f)#이미지 열기 cv2로 열기\n",
    "        #손 색상 변경\n",
    "        ycrb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb) #cv2의 색상을 RGB가 아닌 YCrCb로 변경\n",
    "        img = cv2.inRange(ycrb,np.array([0,133,77]),np.array([255,173,127]))  #해당 색(사람 피부색)에 관련된 색을 구분\n",
    "        img = Image.fromarray(img) #cv2의 이미지를 PIL형식의 이미지로 변경\n",
    "        img = img.convert(\"RGB\")#흑백\n",
    "        img = img.resize((image_w, image_h))#사이즈 변경\n",
    "        data = np.asarray(img)#np.array로 변경\n",
    "        X.append(data) #x에 데이터 \n",
    "        y.append(label) #y에 출력 설정\n",
    "\n",
    "X = np.array(X) # 데이터 전부 모아서 배열 성정\n",
    "y = np.array(y)\n",
    "\n",
    "#학습집합 나누어 주기\n",
    "\n",
    "#X_train y_train 최종학습 집합\n",
    "#X_train_f y_train_f 학습 집합\n",
    "#x_test y_test 테스트 집합\n",
    "#X_vailed y_vailed 검증 집합\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "X_train_f, X_vailed, y_train_f, y_vailed = train_test_split(X_train,y_train)\n",
    "xy = (X_train, X_test, y_train, y_test,X_train_f, X_vailed, y_train_f, y_vailed)\n",
    "\n",
    "\n",
    "np.save(\"./HandGesture/multi_image_data.npy\", xy) #넘파이 배열을 저장해 버림\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 이미지 증식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증식 옵션\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255,rotation_range=30,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.5,zoom_range=0.3,horizontal_flip=True,vertical_flip=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 데이터 불러오기\n",
    "#X_train, X_test, y_train, y_test,X_train_f, X_vailed, y_train_f, y_vailed = np.load('./HandGesture/multi_image_data.npy',allow_pickle=True)\n",
    "\n",
    "# 데이터 증식 적용\n",
    "\n",
    "#학습집합의 데이터 증식\n",
    "train_generator = train_datagen.flow(\n",
    "    x=X_train,y=y_train,\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "#최종 학습 집합 데이터 증식\n",
    "train_f_generator = train_datagen.flow(\n",
    "    x=X_train_f,y=y_train_f,\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "#검증 집합 데이터 증식\n",
    "vailed_generator = train_datagen.flow(\n",
    "    x=X_vailed,y=y_vailed,\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "#테스트 집합 데이터 증식\n",
    "test_generator = train_datagen.flow(\n",
    "    x=X_test,y=y_test,\n",
    "    batch_size = 32,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#카테고리 설정\n",
    "categories = [\"O\", \"V\", \"paper\", \"rock\",\"side\"] \n",
    "nb_classes = len(categories)\n",
    "\n",
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "X_train_f = X_train_f.astype(float) /255\n",
    "X_vailed = X_vailed.astype(float) /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 예제 코드 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmc59\\AppData\\Local\\Temp\\ipykernel_8616\\674420408.py:27: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_1 = model.fit_generator(train_f_generator, epochs=10, validation_data=vailed_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 24s 346ms/step - loss: 1.6390 - accuracy: 0.3411 - val_loss: 1.2675 - val_accuracy: 0.4323\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 22s 336ms/step - loss: 1.2240 - accuracy: 0.4908 - val_loss: 0.8401 - val_accuracy: 0.6885\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 22s 342ms/step - loss: 0.9946 - accuracy: 0.6088 - val_loss: 0.6346 - val_accuracy: 0.7875\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 22s 341ms/step - loss: 0.8368 - accuracy: 0.6846 - val_loss: 0.4610 - val_accuracy: 0.8341\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 22s 340ms/step - loss: 0.6858 - accuracy: 0.7541 - val_loss: 0.5156 - val_accuracy: 0.8355\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 23s 346ms/step - loss: 0.5895 - accuracy: 0.7949 - val_loss: 0.4152 - val_accuracy: 0.8617\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 23s 347ms/step - loss: 0.5248 - accuracy: 0.8328 - val_loss: 0.3280 - val_accuracy: 0.8937\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 22s 346ms/step - loss: 0.4523 - accuracy: 0.8523 - val_loss: 0.2938 - val_accuracy: 0.8996\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 24s 365ms/step - loss: 0.3889 - accuracy: 0.8741 - val_loss: 0.2739 - val_accuracy: 0.9083\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 23s 351ms/step - loss: 0.3661 - accuracy: 0.8746 - val_loss: 0.2109 - val_accuracy: 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', kernel_initializer='he_uniform', padding='same')\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[64, 64, 3]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(), # 2차원을 1차원으로 변환하여 밀집층으로 연결\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(nb_classes, activation='softmax'),\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_dir = './model'\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model1.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history_1 = model.fit_generator(train_f_generator, epochs=10, validation_data=vailed_generator,\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "save_model(model=model,filepath=model_dir+\"/model_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 합성곱 + 최대풀링 섞은 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmc59\\AppData\\Local\\Temp\\ipykernel_8616\\2082454162.py:23: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_2 = model2.fit_generator(train_f_generator, epochs=10, validation_data=vailed_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 11s 159ms/step - loss: 1.0800 - accuracy: 0.6098 - val_loss: 0.6161 - val_accuracy: 0.7875\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 10s 158ms/step - loss: 0.5767 - accuracy: 0.7901 - val_loss: 0.4510 - val_accuracy: 0.8443\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 11s 162ms/step - loss: 0.4261 - accuracy: 0.8508 - val_loss: 0.9099 - val_accuracy: 0.7351\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 10s 159ms/step - loss: 0.3871 - accuracy: 0.8756 - val_loss: 0.3325 - val_accuracy: 0.8923\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 0.2721 - accuracy: 0.9140 - val_loss: 0.2153 - val_accuracy: 0.9316\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 10s 157ms/step - loss: 0.2499 - accuracy: 0.9179 - val_loss: 0.2723 - val_accuracy: 0.9141\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 10s 153ms/step - loss: 0.2288 - accuracy: 0.9271 - val_loss: 0.1700 - val_accuracy: 0.9389\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 10s 160ms/step - loss: 0.2328 - accuracy: 0.9266 - val_loss: 0.2093 - val_accuracy: 0.9403\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 10s 155ms/step - loss: 0.1986 - accuracy: 0.9407 - val_loss: 0.1939 - val_accuracy: 0.9374\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 10s 156ms/step - loss: 0.2095 - accuracy: 0.9373 - val_loss: 0.1666 - val_accuracy: 0.9418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_2\\assets\n"
     ]
    }
   ],
   "source": [
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', kernel_initializer='he_uniform', padding='same')\n",
    "\n",
    "model2 = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[64, 64, 3]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(nb_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_dir = './model'\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model2.h5\", save_best_only=True)\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history_2 = model2.fit_generator(train_f_generator, epochs=10, validation_data=vailed_generator,\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "save_model(model=model2,filepath=model_dir+\"/model_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. VGG 모델 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmc59\\AppData\\Local\\Temp\\ipykernel_8616\\3479977727.py:29: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_3 = model3.fit_generator(train_f_generator, epochs=10, validation_data=vailed_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 16s 247ms/step - loss: 0.6573 - acc: 0.7629 - val_loss: 0.2012 - val_acc: 0.9301\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 16s 240ms/step - loss: 0.3160 - acc: 0.8970 - val_loss: 0.1782 - val_acc: 0.9534\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 16s 243ms/step - loss: 0.2377 - acc: 0.9150 - val_loss: 0.0826 - val_acc: 0.9709\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 16s 250ms/step - loss: 0.2194 - acc: 0.9320 - val_loss: 0.0905 - val_acc: 0.9680\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 0.1492 - acc: 0.9475 - val_loss: 0.0742 - val_acc: 0.9796\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 0.1639 - acc: 0.9485 - val_loss: 0.0486 - val_acc: 0.9767\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 16s 248ms/step - loss: 0.1125 - acc: 0.9645 - val_loss: 0.0580 - val_acc: 0.9840\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 0.1213 - acc: 0.9665 - val_loss: 0.0745 - val_acc: 0.9767\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 16s 239ms/step - loss: 0.0913 - acc: 0.9742 - val_loss: 0.0573 - val_acc: 0.9811\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 16s 244ms/step - loss: 0.0957 - acc: 0.9694 - val_loss: 0.0536 - val_acc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_3\\assets\n"
     ]
    }
   ],
   "source": [
    "def model_maker():\n",
    "    base_model = VGG16(include_top=False, input_shape=(64, 64, 3)) #베이스 모델로는 VGG16 모델을\n",
    "\n",
    "    for layer in base_model.layers[:-2]:\n",
    "        layer.trainable = False # Top 층을 제외한 나머지 층에서 2개의 층을 새롭게 학습 \n",
    " \n",
    "    input1 = Input(shape=(64, 64, 3))\n",
    "    custom_model = base_model(input1)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation='relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input1, outputs=predictions)\n",
    "model3 = model_maker()\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_dir = './model'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "model_path = 'model3.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "\n",
    "history_3 = model3.fit_generator(train_f_generator, epochs=10, validation_data=vailed_generator,\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "save_model(model=model3,filepath=model_dir+\"/model_3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 최종 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmc59\\AppData\\Local\\Temp\\ipykernel_8616\\98138945.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_4 = model4.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 21s 244ms/step - loss: 0.0915 - acc: 0.9698 - val_loss: 0.0699 - val_acc: 0.9770\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 21s 244ms/step - loss: 0.1007 - acc: 0.9676 - val_loss: 0.0326 - val_acc: 0.9891\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 21s 244ms/step - loss: 0.0849 - acc: 0.9716 - val_loss: 0.0604 - val_acc: 0.9803\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 21s 244ms/step - loss: 0.0912 - acc: 0.9709 - val_loss: 0.0540 - val_acc: 0.9749\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 21s 241ms/step - loss: 0.0702 - acc: 0.9752 - val_loss: 0.0401 - val_acc: 0.9836\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 21s 245ms/step - loss: 0.0692 - acc: 0.9785 - val_loss: 0.0319 - val_acc: 0.9880\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 21s 249ms/step - loss: 0.0611 - acc: 0.9811 - val_loss: 0.0275 - val_acc: 0.9880\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0511 - acc: 0.9832 - val_loss: 0.0316 - val_acc: 0.9869\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 21s 247ms/step - loss: 0.0635 - acc: 0.9803 - val_loss: 0.0851 - val_acc: 0.9628\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 21s 247ms/step - loss: 0.0719 - acc: 0.9760 - val_loss: 0.0408 - val_acc: 0.9880\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 21s 242ms/step - loss: 0.0493 - acc: 0.9800 - val_loss: 0.0385 - val_acc: 0.9913\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 21s 245ms/step - loss: 0.0540 - acc: 0.9836 - val_loss: 0.0402 - val_acc: 0.9869\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 21s 244ms/step - loss: 0.0511 - acc: 0.9854 - val_loss: 0.0292 - val_acc: 0.9923\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 21s 239ms/step - loss: 0.0558 - acc: 0.9829 - val_loss: 0.0357 - val_acc: 0.9847\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 21s 239ms/step - loss: 0.0647 - acc: 0.9814 - val_loss: 0.0342 - val_acc: 0.9880\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 21s 239ms/step - loss: 0.0487 - acc: 0.9847 - val_loss: 0.0247 - val_acc: 0.9902\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 21s 244ms/step - loss: 0.0505 - acc: 0.9825 - val_loss: 0.0282 - val_acc: 0.9913\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 21s 241ms/step - loss: 0.0482 - acc: 0.9847 - val_loss: 0.0318 - val_acc: 0.9913\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 21s 241ms/step - loss: 0.0398 - acc: 0.9858 - val_loss: 0.0644 - val_acc: 0.9803\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 20s 238ms/step - loss: 0.0532 - acc: 0.9825 - val_loss: 0.0250 - val_acc: 0.9902\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 20s 236ms/step - loss: 0.0596 - acc: 0.9825 - val_loss: 0.0376 - val_acc: 0.9880\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 21s 247ms/step - loss: 0.0458 - acc: 0.9840 - val_loss: 0.0218 - val_acc: 0.9891\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 22s 254ms/step - loss: 0.0570 - acc: 0.9818 - val_loss: 0.0356 - val_acc: 0.9869\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 23s 267ms/step - loss: 0.0448 - acc: 0.9854 - val_loss: 0.0240 - val_acc: 0.9891\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 22s 254ms/step - loss: 0.0326 - acc: 0.9883 - val_loss: 0.0486 - val_acc: 0.9825\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 22s 261ms/step - loss: 0.0444 - acc: 0.9858 - val_loss: 0.0251 - val_acc: 0.9934\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 21s 245ms/step - loss: 0.0376 - acc: 0.9880 - val_loss: 0.0559 - val_acc: 0.9825\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 21s 239ms/step - loss: 0.0485 - acc: 0.9843 - val_loss: 0.0263 - val_acc: 0.9880\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 21s 248ms/step - loss: 0.0280 - acc: 0.9880 - val_loss: 0.0309 - val_acc: 0.9891\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 21s 247ms/step - loss: 0.0381 - acc: 0.9869 - val_loss: 0.0127 - val_acc: 0.9956\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0318 - acc: 0.9887 - val_loss: 0.0231 - val_acc: 0.9923\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 21s 247ms/step - loss: 0.0321 - acc: 0.9898 - val_loss: 0.0263 - val_acc: 0.9880\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 21s 244ms/step - loss: 0.0411 - acc: 0.9854 - val_loss: 0.0144 - val_acc: 0.9956\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 21s 243ms/step - loss: 0.0307 - acc: 0.9883 - val_loss: 0.0151 - val_acc: 0.9934\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 21s 240ms/step - loss: 0.0285 - acc: 0.9923 - val_loss: 0.0216 - val_acc: 0.9923\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 21s 242ms/step - loss: 0.0292 - acc: 0.9898 - val_loss: 0.0466 - val_acc: 0.9869\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 21s 245ms/step - loss: 0.0454 - acc: 0.9847 - val_loss: 0.0226 - val_acc: 0.9902\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 21s 245ms/step - loss: 0.0285 - acc: 0.9887 - val_loss: 0.0158 - val_acc: 0.9934\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 21s 242ms/step - loss: 0.0277 - acc: 0.9898 - val_loss: 0.0263 - val_acc: 0.9902\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 20s 236ms/step - loss: 0.0476 - acc: 0.9854 - val_loss: 0.0271 - val_acc: 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_Last\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/model_Last\\assets\n"
     ]
    }
   ],
   "source": [
    "#최종모델 불러오기\n",
    "#model4 = load_model('./model/model_Last')\n",
    "\n",
    "model4 = model3\n",
    "history_4 = model4.fit_generator(train_generator,\n",
    "                        epochs=100,\n",
    "                        validation_data=test_generator,\n",
    "                        callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "save_model(model=model4,filepath=model_dir+\"/model_Last\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1최종 모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 2, 2, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,747,845\n",
      "Trainable params: 2,392,965\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 최종 모델 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 5s 158ms/step - loss: 0.0137 - acc: 0.9923\n",
      "정확도 : 0.9923\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model3.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 최종 모델 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history_3.history['val_loss']\n",
    "y_loss = history_3.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import * #GUI\n",
    "import numpy as np \n",
    "import cv2 #웹캠\n",
    "import screen_brightness_control as sbc #화면 밝기 조절\n",
    "import pyautogui #볼륨 업 다운\n",
    "import keyboard\n",
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "#  예제 1) tkinter 파이썬 GUI 레이블(label)\n",
    "# tkinter를 사용하여 텍스트를 나타내보자\n",
    "# 1. 루트화면 (root window) 생성\n",
    "\n",
    "def chgkey(x):\n",
    "    if x == 1: #o\n",
    "        pyautogui.press('volumeup')\n",
    "    elif x == 2: #v\n",
    "        pyautogui.press('volumedown')\n",
    "    elif x == 3: #r\n",
    "        pyautogui.press('volumemute')   \n",
    "\n",
    "def cam():\n",
    "    cv2.imwrite(\"self camera test.jpg\", frame) # 사진 저장\n",
    "\n",
    "\n",
    "brightness = sbc.get_brightness()\n",
    "b = brightness[0]\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "y=1\n",
    "\n",
    "while(True):\n",
    "    ret, frame = capture.read() \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2YCrCb)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cam()\n",
    "        \n",
    "        caltech_dir = \"./\"\n",
    "        image_w = 64\n",
    "        image_h = 64\n",
    "\n",
    "        pixels = image_h * image_w * 3\n",
    "\n",
    "        X = []\n",
    "        filenames = []\n",
    "        files = glob.glob(caltech_dir+\"self camera test.jpg\")\n",
    "\n",
    "        for i, f in enumerate(files):\n",
    "            img = cv2.imread(f)#이미지 열고\n",
    "            #손 색상 변경\n",
    "            ycrb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)\n",
    "            img = cv2.inRange(ycrb,np.array([0,133,77]),np.array([255,173,127])) \n",
    "            img = Image.fromarray(img)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((image_w, image_h))\n",
    "            #img.show()\n",
    "            data = np.asarray(img)\n",
    "            filenames.append(f)\n",
    "            X.append(data)\n",
    "\n",
    "        X = np.array(X)\n",
    "        model = load_model('./model/model_Last')\n",
    "\n",
    "        prediction = model.predict(X)\n",
    "        np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "        cnt = 0\n",
    "        #이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "        for i in prediction:\n",
    "            pre_ans = i.argmax()  # 예측 레이블\n",
    "            print(i)\n",
    "            print(pre_ans)\n",
    "            pre_ans_str = ''\n",
    "            if pre_ans == 0: pre_ans_str = \"o\"\n",
    "            elif pre_ans == 1: pre_ans_str = \"V\"\n",
    "            elif pre_ans == 2: pre_ans_str = \"paper\"\n",
    "            elif pre_ans == 3: pre_ans_str = \"rock\"\n",
    "            elif pre_ans == 4: pre_ans_str = \"side\"\n",
    "            \n",
    "            if i[0] >= 0.8 : \n",
    "                print(\"o\")\n",
    "                y=4\n",
    "            if i[1] >= 0.8: \n",
    "                print(\"v\")\n",
    "                y=5\n",
    "            if i[2] >= 0.8:\n",
    "                print(\"paper\") \n",
    "                y=1\n",
    "            if i[3] >= 0.8:\n",
    "                print(\"rock\") \n",
    "                y=2\n",
    "            if i[4] >= 0.8:\n",
    "                print(\"side\") \n",
    "                y=3\n",
    "            cnt += 1\n",
    "            \n",
    "\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에.\n",
    "    \n",
    "            #모델로 어떤 기능인지 파악 1, 2, 3, 4 ,5 값을 리턴\n",
    "        if y == 1:\n",
    "            chgkey(1)\n",
    "        elif y == 2:\n",
    "            chgkey(2)\n",
    "        elif y == 3:\n",
    "            chgkey(3)\n",
    "        elif y == 4:\n",
    "            brightness[0] -= 10\n",
    "            if brightness[0] < 0 :\n",
    "                brightness[0] = 0\n",
    "            sbc.set_brightness(brightness[0])\n",
    "        elif y == 5:\n",
    "            brightness[0] += 10\n",
    "            if brightness[0] > 100:\n",
    "                brightness[0] = 100\n",
    "            sbc.set_brightness(brightness[0])\n",
    "        else : \n",
    "            print(\"인식되지 않음\")\n",
    "        \n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 번외 사진으로 테스트 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caltech_dir = \"./HandGesture/test\"\\nimage_w = 64\\nimage_h = 64\\n\\npixels = image_h * image_w * 3\\n\\nX = []\\nfilenames = []\\nfiles = glob.glob(caltech_dir+\"/*.*\")\\n\\nfor i, f in enumerate(files):\\n    img = cv2.imread(f)#이미지 열고\\n    #손 색상 변경\\n    ycrb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)\\n    img = cv2.inRange(ycrb,np.array([0,133,77]),np.array([255,173,127])) \\n    img = Image.fromarray(img)\\n    img = img.convert(\"RGB\")\\n    img = img.resize((image_w, image_h))\\n    #img.show()\\n    data = np.asarray(img)\\n    filenames.append(f)\\n    X.append(data)\\n\\nX = np.array(X)\\nmodel = load_model(\\'./model_Last\\')\\n\\nprediction = model.predict(X)\\nnp.set_printoptions(formatter={\\'float\\': lambda x: \"{0:0.3f}\".format(x)})\\ncnt = 0\\n\\n#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\\nfor i in prediction:\\n    pre_ans = i.argmax()  # 예측 레이블\\n    print(i)\\n    print(pre_ans)\\n    pre_ans_str = \\'\\'\\n    if pre_ans == 0: pre_ans_str = \"o\"\\n    elif pre_ans == 1: pre_ans_str = \"V\"\\n    elif pre_ans == 2: pre_ans_str = \"paper\"\\n    elif pre_ans == 3: pre_ans_str = \"rock\"\\n    else: pre_ans_str = \"side\"\\n   \\n    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\\n    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\\n    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\\n    if i[3] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\\n    if i[4] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\\n    cnt += 1\\n    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\\n    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\\n    # 이걸 한 것은 _4.py에.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"caltech_dir = \"./HandGesture/test\"\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    img = cv2.imread(f)#이미지 열고\n",
    "    #손 색상 변경\n",
    "    ycrb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)\n",
    "    img = cv2.inRange(ycrb,np.array([0,133,77]),np.array([255,173,127])) \n",
    "    img = Image.fromarray(img)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    #img.show()\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "model = load_model('./model_Last')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    print(i)\n",
    "    print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"o\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"V\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"paper\"\n",
    "    elif pre_ans == 3: pre_ans_str = \"rock\"\n",
    "    else: pre_ans_str = \"side\"\n",
    "   \n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[3] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[4] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b961d8f9206faaef7d3163d24c626b65937dc11e9ce5e74e2ec94a8fdbcc7de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
